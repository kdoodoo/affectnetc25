# AffectNetC25


**Dataset Composition**
|Experiment Set I | 800 Confuning Images |
| ------------- | ------------- |
|Experiment Set II | 800 Random Images |

8 Expressions
Code = <br />
{'happiness': 0, <br />
 'sadness': 1, <br />
 'surprise': 2, <br />
 'fear': 3, <br />
 'disgust': 4, <br />
 'anger': 5, <br />
 'contempt': 6, <br />
 'neutral': 7} <br />


Arousal and Valence 
|Affective Rating | Range|
| ------------- | ------------- |
|Arousal | -1.00, -0.75. -0.50, -0.25, 0.00, 0.25, 0.50, 0.75, 1.00|
|Valence |  -1.00, -0.75. -0.50, -0.25, 0.00, 0.25, 0.50, 0.75, 1.00|






**Original model links**

|MODEL  | LINK |
| ------------- | ------------- |
| ResNet50  |[LINK](https://www.tensorflow.org/api_docs/python/tf/keras/applications/resnet50/ResNet50) |
| B2, AFEW, VGAF  |[LINK](https://github.com/av-savchenko/face-emotion-recognition) |
| EMONET  |[LINK](https://github.com/face-analysis/emonet) |
| DAN  |[LINK](https://github.com/yaoing/DAN) |
